"use strict";(self.webpackChunkcarol_soares_blog=self.webpackChunkcarol_soares_blog||[]).push([[4076],{1940:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>d});var r=s(4446),i=s(4848),a=s(8453);const t={slug:"large-language-models-llm",title:"What is a Large Language Model (LLM)?",authors:"carolsoares",tags:["ai","llm","generative ai","product-development"],description:"A simple yet technical guide to understanding Large Language Models (LLMs) and how they\u2019re reshaping the way we build products."},l="What Is a Large Language Model (LLM)?",o={authorsImageUrls:[void 0]},d=[{value:"What Exactly Is a Large Language Model?",id:"what-exactly-is-a-large-language-model",level:2},{value:"How Are LLMs Created?",id:"how-are-llms-created",level:2},{value:"Tools That Power LLM Development",id:"tools-that-power-llm-development",level:3},{value:"How Do LLMs Actually Learn?",id:"how-do-llms-actually-learn",level:2},{value:"Training at Scale: Think Brain Meets Gym",id:"training-at-scale-think-brain-meets-gym",level:2},{value:"What Happens After Training?",id:"what-happens-after-training",level:2},{value:"Where Are LLMs Being Used?",id:"where-are-llms-being-used",level:2},{value:"How Developers Use LLMs Every Day",id:"how-developers-use-llms-every-day",level:2},{value:"1. <strong>OpenAI GPT (ChatGPT)</strong>",id:"1-openai-gpt-chatgpt",level:3},{value:"2. <strong>Google PaLM 2 / Gemini</strong>",id:"2-google-palm-2--gemini",level:3},{value:"3. <strong>Anthropic Claude</strong>",id:"3-anthropic-claude",level:3},{value:"4. <strong>Meta LLaMA (Open Source)</strong>",id:"4-meta-llama-open-source",level:3},{value:"5. <strong>Hugging Face Transformers</strong>",id:"5-hugging-face-transformers",level:3},{value:"LLMs in Products: Real Examples",id:"llms-in-products-real-examples",level:2},{value:"\u2764\ufe0f Final Thoughts",id:"\ufe0f-final-thoughts",level:2},{value:"Useful Links Recap",id:"useful-links-recap",level:2}];function c(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["Hey everyone! \ud83d\udcbb\u2728 ",(0,i.jsx)("br",{})]}),"\n",(0,i.jsxs)(n.p,{children:["Today I want to talk about something I\u2019ve been working: ",(0,i.jsx)(n.strong,{children:"Large Language Models"})," (LLMs). If you've been hearing a lot about ChatGPT, Bard, Claude, or LLaMA and wondered ",(0,i.jsx)(n.em,{children:"what all the buzz is about"})," \u2014 I\u2019ve got you. Let\u2019s break it down in a clear and friendly way."]}),"\n",(0,i.jsx)(n.h2,{id:"what-exactly-is-a-large-language-model",children:"What Exactly Is a Large Language Model?"}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.strong,{children:"Large Language Model"})," is a type of ",(0,i.jsx)(n.strong,{children:"artificial intelligence"})," designed to understand and generate human language. Think of it as a super smart assistant that\u2019s read massive amounts of data \u2014 books, articles, code, forum posts, and even images or videos \u2014 and now knows how to generate coherent and useful text responses. \ud83e\udd2f"]}),"\n",(0,i.jsxs)(n.p,{children:["They're called ",(0,i.jsx)(n.em,{children:'"large"'})," because they contain billions (and sometimes trillions!) of parameters \u2014 which are essentially learned settings that help the model detect patterns in language."]}),"\n",(0,i.jsx)(n.h2,{id:"how-are-llms-created",children:"How Are LLMs Created?"}),"\n",(0,i.jsxs)(n.p,{children:["Everything starts with ",(0,i.jsx)(n.strong,{children:"training"})," \u2014 and here\u2019s where things get a little technical, but in a good way."]}),"\n",(0,i.jsxs)(n.p,{children:["At the core of most LLMs is a deep learning architecture called the ",(0,i.jsx)(n.strong,{children:"Transformer"}),", introduced by Google in 2017. (For the curious minds, here\u2019s the original ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/1706.03762",children:"\u201cAttention Is All You Need\u201d"})," paper.) This architecture revolutionized the way we work with language in AI by making it possible to model relationships between words over long distances in a text."]}),"\n",(0,i.jsxs)(n.p,{children:["Rather than analyzing words one at a time, Transformers allow the model to understand entire sequences at once \u2014 similar to how ",(0,i.jsx)(n.em,{children:"you"})," read a message and instantly understands its meaning, even without emojis or GIFs. \ud83d\udcac"]}),"\n",(0,i.jsx)(n.h3,{id:"tools-that-power-llm-development",children:"Tools That Power LLM Development"}),"\n",(0,i.jsxs)(n.p,{children:["Most LLMs are developed using ",(0,i.jsx)(n.strong,{children:"Python"}),", alongside popular deep learning libraries like:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"PyTorch"})," \u2013 widely used in research and production"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TensorFlow"})," \u2013 known for its scalability and performance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"JAX"})," \u2013 favored by Google for high-performance model training"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"These frameworks help build the model\u2019s internal architecture, which includes:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Embedding layers"})," \u2013 turn words into vector representations the model can process"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multi-head self-attention"}),' \u2013 lets the model "pay attention" to all words in a sentence at once']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Feed-forward neural networks"})," \u2013 deepen the understanding of context"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Layer normalization and residual connections"})," \u2013 stabilize the learning process"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["These components are stacked dozens of times (up to 96 layers in models like GPT-4), resulting in deep networks with ",(0,i.jsx)(n.em,{children:"massive"})," capacity for language understanding."]}),"\n",(0,i.jsx)(n.h2,{id:"how-do-llms-actually-learn",children:"How Do LLMs Actually Learn?"}),"\n",(0,i.jsxs)(n.p,{children:["LLMs are trained using ",(0,i.jsx)(n.strong,{children:"self-supervised learning"}),", which means they learn by predicting words in vast amounts of unlabeled text."]}),"\n",(0,i.jsx)(n.p,{children:"There are two common objectives:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Causal Language Modeling (CLM)"})," \u2013 Predict the ",(0,i.jsx)(n.em,{children:"next"})," word in a sentence (e.g., GPT)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Masked Language Modeling (MLM)"})," \u2013 Predict ",(0,i.jsx)(n.em,{children:"missing"})," words in a sentence (e.g., BERT)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"To learn, the model uses:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Backpropagation"})," \u2013 a mathematical technique for adjusting internal parameters based on mistakes"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gradient descent"})," \u2013 an optimization method that helps the model improve gradually with each example"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"With time and repetition, the model becomes excellent at predicting what comes next in a sentence \u2014 which is exactly what allows it to write stories, generate code, answer questions, and so much more."}),"\n",(0,i.jsx)(n.h2,{id:"training-at-scale-think-brain-meets-gym",children:"Training at Scale: Think Brain Meets Gym"}),"\n",(0,i.jsxs)(n.p,{children:["Training an LLM is like putting a super brain in a data gym \u2014 for ",(0,i.jsx)(n.em,{children:"weeks"})," or even ",(0,i.jsx)(n.em,{children:"months"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"It requires:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Hardware"}),": Hundreds to thousands of GPUs (e.g., NVIDIA A100s) or TPUs"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Data"}),": Terabytes of curated text \u2014 books, articles, forums, code repositories, etc."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Optimization techniques"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mixed precision training"})," (for memory efficiency)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gradient checkpointing"})," (to reduce memory usage)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data/model parallelism"})," (to spread the workload across multiple devices)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"what-happens-after-training",children:"What Happens After Training?"}),"\n",(0,i.jsx)(n.p,{children:"Once the model is trained, it can be:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fine-tuned"})," for specific domains (e.g., healthcare, law, customer support)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Aligned"})," with human values using ",(0,i.jsx)(n.strong,{children:"Reinforcement Learning from Human Feedback (RLHF)"})," \u2014 the secret sauce behind ChatGPT\u2019s natural tone"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"where-are-llms-being-used",children:"Where Are LLMs Being Used?"}),"\n",(0,i.jsx)(n.p,{children:"Everywhere! Some real-world applications include:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Chatbots"})," and ",(0,i.jsx)(n.strong,{children:"virtual assistants"})," (like ChatGPT, Bard, Copilot)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Internal knowledge bases"})," and ",(0,i.jsx)(n.strong,{children:"customer support tools"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Coding assistants"})," (GitHub Copilot, Cody, etc.)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Business intelligence"})," (summarizing reports, extracting insights)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Education"})," (tutoring, quiz generation)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Marketing & eCommerce"})," (product descriptions, reviews, emails)"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"how-developers-use-llms-every-day",children:"How Developers Use LLMs Every Day"}),"\n",(0,i.jsx)(n.p,{children:"LLMs are easier to integrate than ever \u2014 here\u2019s how devs can use them right now:"}),"\n",(0,i.jsxs)(n.h3,{id:"1-openai-gpt-chatgpt",children:["1. ",(0,i.jsx)(n.strong,{children:"OpenAI GPT (ChatGPT)"})]}),"\n",(0,i.jsxs)(n.p,{children:["Use the ",(0,i.jsx)(n.a,{href:"https://platform.openai.com/docs",children:"OpenAI API"})," to add ",(0,i.jsx)(n.code,{children:"gpt-4"})," or ",(0,i.jsx)(n.code,{children:"gpt-3.5-turbo"})," to your apps."]}),"\n",(0,i.jsx)(n.p,{children:"Use cases:\nChatbots, AI helpdesks, content generation, code explanation, test generation."}),"\n",(0,i.jsxs)(n.h3,{id:"2-google-palm-2--gemini",children:["2. ",(0,i.jsx)(n.strong,{children:"Google PaLM 2 / Gemini"})]}),"\n",(0,i.jsxs)(n.p,{children:["Google Cloud\u2019s ",(0,i.jsx)(n.a,{href:"https://cloud.google.com/vertex-ai/docs/generative-ai/overview",children:"Vertex AI"})," supports powerful LLMs for enterprise apps."]}),"\n",(0,i.jsx)(n.p,{children:"Use cases:\nMultimodal apps, enterprise search, document analysis."}),"\n",(0,i.jsxs)(n.h3,{id:"3-anthropic-claude",children:["3. ",(0,i.jsx)(n.strong,{children:"Anthropic Claude"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://www.anthropic.com/index/introducing-claude",children:"Claude"})," is known for its thoughtful responses and safe design. Great for structured Q&A and summarization."]}),"\n",(0,i.jsxs)(n.h3,{id:"4-meta-llama-open-source",children:["4. ",(0,i.jsx)(n.strong,{children:"Meta LLaMA (Open Source)"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://ai.meta.com/llama/",children:"Meta\u2019s LLaMA"})," models are open-source and ideal for:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Privacy-first apps"})," \u2013 Your users' data stays with you"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"On-device AI"})," \u2013 No internet? No problem"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Lightweight experimentation"})," \u2013 Great for prototyping without cloud costs"]}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"5-hugging-face-transformers",children:["5. ",(0,i.jsx)(n.strong,{children:"Hugging Face Transformers"})]}),"\n",(0,i.jsxs)(n.p,{children:["The ultimate playground for developers and researchers.\n",(0,i.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/index",children:"HuggingFace Transformers"})," lets you load and test LLMs like GPT, T5, BERT, and more:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install transformers\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from transformers import pipeline\n\ngenerator = pipeline("text-generation", model="gpt2")\nprint(generator("Once upon a time,", max_length=50))\n'})}),"\n",(0,i.jsx)(n.h2,{id:"llms-in-products-real-examples",children:"LLMs in Products: Real Examples"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"E-commerce"}),": Smart descriptions, review summaries, product Q&A"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"EdTech"}),": Lesson planners, tutoring, content feedback"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Healthcare"}),": Summarizing notes, answering medical FAQs (responsibly)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Business"}),": Analyzing emails, reports, and meeting summaries"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-final-thoughts",children:"\u2764\ufe0f Final Thoughts"}),"\n",(0,i.jsx)(n.p,{children:"We\u2019re only scratching the surface of what LLMs can do. As developers, product builders, and creators, we\u2019re in a moment of incredible opportunity."}),"\n",(0,i.jsx)(n.p,{children:"\u2728 Start small \u2014 test an API, build a chatbot, experiment with a prompt.\nYou\u2019ll be surprised how far your creativity can take you with these tools at your side."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"useful-links-recap",children:"Useful Links Recap"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://platform.openai.com/docs",children:"OpenAI GPT API Docs"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/index",children:"HuggingFace Transformers"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://cloud.google.com/vertex-ai/docs/generative-ai/overview",children:"Google Vertex AI"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.anthropic.com/index/introducing-claude",children:"Anthropic Claude"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://ai.meta.com/llama/",children:"Meta LLaMA"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/1706.03762",children:"\u201cAttention is All You Need\u201d (original paper)"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Large_language_model",children:"Large language model \u2013 Wikipedia"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},4446:e=>{e.exports=JSON.parse('{"permalink":"/carol-soares-blog/blog/large-language-models-llm","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-05-31-about-llm.md","source":"@site/blog/2025-05-31-about-llm.md","title":"What is a Large Language Model (LLM)?","description":"A simple yet technical guide to understanding Large Language Models (LLMs) and how they\u2019re reshaping the way we build products.","date":"2025-05-31T00:00:00.000Z","tags":[{"inline":true,"label":"ai","permalink":"/carol-soares-blog/blog/tags/ai"},{"inline":true,"label":"llm","permalink":"/carol-soares-blog/blog/tags/llm"},{"inline":true,"label":"generative ai","permalink":"/carol-soares-blog/blog/tags/generative-ai"},{"inline":true,"label":"product-development","permalink":"/carol-soares-blog/blog/tags/product-development"}],"readingTime":5.07,"hasTruncateMarker":false,"authors":[{"name":"Carol Soares","title":"Backend Enginner @ Thoughtworks","url":"https://github.com/carolinesoarws","page":{"permalink":"/carol-soares-blog/blog/authors/carolsoares"},"socials":{"linkedin":"https://www.linkedin.com/in/caroline-soares-0ba238107/","github":"https://github.com/carolinesoarws"},"imageURL":"https://avatars.githubusercontent.com/u/83501330?v=4","key":"carolsoares"}],"frontMatter":{"slug":"large-language-models-llm","title":"What is a Large Language Model (LLM)?","authors":"carolsoares","tags":["ai","llm","generative ai","product-development"],"description":"A simple yet technical guide to understanding Large Language Models (LLMs) and how they\u2019re reshaping the way we build products."},"unlisted":false,"nextItem":{"title":"My Experience at TheDevConf 2025","permalink":"/carol-soares-blog/blog/dtc-conference"}}')},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var r=s(6540);const i={},a=r.createContext(i);function t(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);