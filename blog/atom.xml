<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="atom.xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://carolinesoarws.github.io/carol-soares-blog/blog</id>
    <title>Carol Soares Blog Blog</title>
    <updated>2025-05-31T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://carolinesoarws.github.io/carol-soares-blog/blog"/>
    <subtitle>Carol Soares Blog Blog</subtitle>
    <icon>https://carolinesoarws.github.io/carol-soares-blog/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[What is a Large Language Model (LLM)?]]></title>
        <id>https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm</id>
        <link href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm"/>
        <updated>2025-05-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A simple yet technical guide to understanding Large Language Models (LLMs) and how they‚Äôre reshaping the way we build products.]]></summary>
        <content type="html"><![CDATA[<p>Hey everyone! üíª‚ú® <br></p>
<p>Today I want to talk about something I‚Äôve been working: <strong>Large Language Models</strong> (LLMs). If you've been hearing a lot about ChatGPT, Bard, Claude, or LLaMA and wondered <em>what all the buzz is about</em> ‚Äî I‚Äôve got you. Let‚Äôs break it down in a clear and friendly way.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-exactly-is-a-large-language-model">What Exactly Is a Large Language Model?<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#what-exactly-is-a-large-language-model" class="hash-link" aria-label="Direct link to What Exactly Is a Large Language Model?" title="Direct link to What Exactly Is a Large Language Model?">‚Äã</a></h2>
<p>A <strong>Large Language Model</strong> is a type of <strong>artificial intelligence</strong> designed to understand and generate human language. Think of it as a super smart assistant that‚Äôs read massive amounts of data ‚Äî books, articles, code, forum posts, and even images or videos ‚Äî and now knows how to generate coherent and useful text responses. ü§Ø</p>
<p>They're called <em>"large"</em> because they contain billions (and sometimes trillions!) of parameters ‚Äî which are essentially learned settings that help the model detect patterns in language.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-are-llms-created">How Are LLMs Created?<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#how-are-llms-created" class="hash-link" aria-label="Direct link to How Are LLMs Created?" title="Direct link to How Are LLMs Created?">‚Äã</a></h2>
<p>Everything starts with <strong>training</strong> ‚Äî and here‚Äôs where things get a little technical, but in a good way.</p>
<p>At the core of most LLMs is a deep learning architecture called the <strong>Transformer</strong>, introduced by Google in 2017. (For the curious minds, here‚Äôs the original <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">‚ÄúAttention Is All You Need‚Äù</a> paper.) This architecture revolutionized the way we work with language in AI by making it possible to model relationships between words over long distances in a text.</p>
<p>Rather than analyzing words one at a time, Transformers allow the model to understand entire sequences at once ‚Äî similar to how <em>you</em> read a message and instantly understands its meaning, even without emojis or GIFs. üí¨</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tools-that-power-llm-development">Tools That Power LLM Development<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#tools-that-power-llm-development" class="hash-link" aria-label="Direct link to Tools That Power LLM Development" title="Direct link to Tools That Power LLM Development">‚Äã</a></h3>
<p>Most LLMs are developed using <strong>Python</strong>, alongside popular deep learning libraries like:</p>
<ul>
<li><strong>PyTorch</strong> ‚Äì widely used in research and production</li>
<li><strong>TensorFlow</strong> ‚Äì known for its scalability and performance</li>
<li><strong>JAX</strong> ‚Äì favored by Google for high-performance model training</li>
</ul>
<p>These frameworks help build the model‚Äôs internal architecture, which includes:</p>
<ul>
<li><strong>Embedding layers</strong> ‚Äì turn words into vector representations the model can process</li>
<li><strong>Multi-head self-attention</strong> ‚Äì lets the model "pay attention" to all words in a sentence at once</li>
<li><strong>Feed-forward neural networks</strong> ‚Äì deepen the understanding of context</li>
<li><strong>Layer normalization and residual connections</strong> ‚Äì stabilize the learning process</li>
</ul>
<p>These components are stacked dozens of times (up to 96 layers in models like GPT-4), resulting in deep networks with <em>massive</em> capacity for language understanding.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-do-llms-actually-learn">How Do LLMs Actually Learn?<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#how-do-llms-actually-learn" class="hash-link" aria-label="Direct link to How Do LLMs Actually Learn?" title="Direct link to How Do LLMs Actually Learn?">‚Äã</a></h2>
<p>LLMs are trained using <strong>self-supervised learning</strong>, which means they learn by predicting words in vast amounts of unlabeled text.</p>
<p>There are two common objectives:</p>
<ul>
<li><strong>Causal Language Modeling (CLM)</strong> ‚Äì Predict the <em>next</em> word in a sentence (e.g., GPT)</li>
<li><strong>Masked Language Modeling (MLM)</strong> ‚Äì Predict <em>missing</em> words in a sentence (e.g., BERT)</li>
</ul>
<p>To learn, the model uses:</p>
<ul>
<li><strong>Backpropagation</strong> ‚Äì a mathematical technique for adjusting internal parameters based on mistakes</li>
<li><strong>Gradient descent</strong> ‚Äì an optimization method that helps the model improve gradually with each example</li>
</ul>
<p>With time and repetition, the model becomes excellent at predicting what comes next in a sentence ‚Äî which is exactly what allows it to write stories, generate code, answer questions, and so much more.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="training-at-scale-a-super-brain-goes-to-the-gym">Training at Scale: A Super Brain Goes To the Gym<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#training-at-scale-a-super-brain-goes-to-the-gym" class="hash-link" aria-label="Direct link to Training at Scale: A Super Brain Goes To the Gym" title="Direct link to Training at Scale: A Super Brain Goes To the Gym">‚Äã</a></h2>
<p>Training an LLM is like sending a super-brain to bootcamp ‚Äî lifting data instead of weights ‚Äî for <em>weeks</em> or even <em>months</em>.</p>
<p>It requires:</p>
<ul>
<li>
<p><strong>Hardware</strong>: Hundreds to thousands of GPUs (e.g., NVIDIA A100s) or TPUs</p>
</li>
<li>
<p><strong>Data</strong>: Terabytes of curated text ‚Äî books, articles, forums, code repositories, etc.</p>
</li>
<li>
<p><strong>Optimization techniques</strong>:</p>
<ul>
<li><strong>Mixed precision training</strong> (for memory efficiency)</li>
<li><strong>Gradient checkpointing</strong> (to reduce memory usage)</li>
<li><strong>Data/model parallelism</strong> (to spread the workload across multiple devices)</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-happens-after-training">What Happens After Training?<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#what-happens-after-training" class="hash-link" aria-label="Direct link to What Happens After Training?" title="Direct link to What Happens After Training?">‚Äã</a></h2>
<p>Once the model is trained, it can be:</p>
<ul>
<li><strong>Fine-tuned</strong> for specific domains (e.g., healthcare, law, customer support)</li>
<li><strong>Aligned</strong> with human values using <strong>Reinforcement Learning from Human Feedback (RLHF)</strong> ‚Äî the secret sauce behind ChatGPT‚Äôs natural tone</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="where-are-llms-being-used">Where Are LLMs Being Used?<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#where-are-llms-being-used" class="hash-link" aria-label="Direct link to Where Are LLMs Being Used?" title="Direct link to Where Are LLMs Being Used?">‚Äã</a></h2>
<p>Everywhere! Some real-world applications include:</p>
<ul>
<li><strong>Chatbots</strong> and <strong>virtual assistants</strong> (like ChatGPT, Bard, Copilot)</li>
<li><strong>Internal knowledge bases</strong> and <strong>customer support tools</strong></li>
<li><strong>Coding assistants</strong> (GitHub Copilot, Cody, etc.)</li>
<li><strong>Business intelligence</strong> (summarizing reports, extracting insights)</li>
<li><strong>Education</strong> (tutoring, quiz generation)</li>
<li><strong>Marketing &amp; eCommerce</strong> (product descriptions, reviews, emails)</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-developers-use-llms-every-day">How Developers Use LLMs Every Day<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#how-developers-use-llms-every-day" class="hash-link" aria-label="Direct link to How Developers Use LLMs Every Day" title="Direct link to How Developers Use LLMs Every Day">‚Äã</a></h2>
<p>LLMs are easier to integrate than ever ‚Äî here‚Äôs how devs can use them right now:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-openai-gpt-chatgpt">1. <strong>OpenAI GPT (ChatGPT)</strong><a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#1-openai-gpt-chatgpt" class="hash-link" aria-label="Direct link to 1-openai-gpt-chatgpt" title="Direct link to 1-openai-gpt-chatgpt">‚Äã</a></h3>
<p>Use the <a href="https://platform.openai.com/docs" target="_blank" rel="noopener noreferrer">OpenAI API</a> to add <code>gpt-4</code> or <code>gpt-3.5-turbo</code> to your apps.</p>
<p>Use cases:
Chatbots, AI helpdesks, content generation, code explanation, test generation.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-google-palm-2--gemini">2. <strong>Google PaLM 2 / Gemini</strong><a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#2-google-palm-2--gemini" class="hash-link" aria-label="Direct link to 2-google-palm-2--gemini" title="Direct link to 2-google-palm-2--gemini">‚Äã</a></h3>
<p>Google Cloud‚Äôs <a href="https://cloud.google.com/vertex-ai/docs/generative-ai/overview" target="_blank" rel="noopener noreferrer">Vertex AI</a> supports powerful LLMs for enterprise apps.</p>
<p>Use cases:
Multimodal apps, enterprise search, document analysis.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-anthropic-claude">3. <strong>Anthropic Claude</strong><a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#3-anthropic-claude" class="hash-link" aria-label="Direct link to 3-anthropic-claude" title="Direct link to 3-anthropic-claude">‚Äã</a></h3>
<p><a href="https://www.anthropic.com/index/introducing-claude" target="_blank" rel="noopener noreferrer">Claude</a> is known for its thoughtful responses and safe design. Great for structured Q&amp;A and summarization.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-meta-llama-open-source">4. <strong>Meta LLaMA (Open Source)</strong><a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#4-meta-llama-open-source" class="hash-link" aria-label="Direct link to 4-meta-llama-open-source" title="Direct link to 4-meta-llama-open-source">‚Äã</a></h3>
<p><a href="https://ai.meta.com/llama/" target="_blank" rel="noopener noreferrer">Meta‚Äôs LLaMA</a> models are open-source and ideal for:</p>
<ul>
<li><strong>Privacy-first apps</strong> ‚Äì Your users' data stays with you</li>
<li><strong>On-device AI</strong> ‚Äì No internet? No problem</li>
<li><strong>Lightweight experimentation</strong> ‚Äì Great for prototyping without cloud costs</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="5-hugging-face-transformers">5. <strong>Hugging Face Transformers</strong><a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#5-hugging-face-transformers" class="hash-link" aria-label="Direct link to 5-hugging-face-transformers" title="Direct link to 5-hugging-face-transformers">‚Äã</a></h3>
<p>The ultimate playground for developers and researchers.
<a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener noreferrer">HuggingFace Transformers</a> lets you load and test LLMs like GPT, T5, BERT, and more:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install transformers</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> pipeline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">generator </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"text-generation"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"gpt2"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">generator</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Once upon a time,"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> max_length</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">50</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llms-in-products-real-examples">LLMs in Products: Real Examples<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#llms-in-products-real-examples" class="hash-link" aria-label="Direct link to LLMs in Products: Real Examples" title="Direct link to LLMs in Products: Real Examples">‚Äã</a></h2>
<ul>
<li><strong>E-commerce</strong>: Smart descriptions, review summaries, product Q&amp;A</li>
<li><strong>EdTech</strong>: Lesson planners, tutoring, content feedback</li>
<li><strong>Healthcare</strong>: Summarizing notes, answering medical FAQs (responsibly)</li>
<li><strong>Business</strong>: Analyzing emails, reports, and meeting summaries</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="Ô∏è-final-thoughts">‚ù§Ô∏è Final Thoughts<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#%EF%B8%8F-final-thoughts" class="hash-link" aria-label="Direct link to ‚ù§Ô∏è Final Thoughts" title="Direct link to ‚ù§Ô∏è Final Thoughts">‚Äã</a></h2>
<p>We‚Äôre only scratching the surface of what LLMs can do. As developers, product builders, and creators, we‚Äôre in a moment of incredible opportunity.</p>
<p>‚ú® Start small ‚Äî test an API, build a chatbot, experiment with a prompt.
You‚Äôll be surprised how far your creativity can take you with these tools at your side.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="useful-links-recap">Useful Links Recap<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/large-language-models-llm#useful-links-recap" class="hash-link" aria-label="Direct link to Useful Links Recap" title="Direct link to Useful Links Recap">‚Äã</a></h2>
<ul>
<li><a href="https://platform.openai.com/docs" target="_blank" rel="noopener noreferrer">OpenAI GPT API Docs</a></li>
<li><a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener noreferrer">HuggingFace Transformers</a></li>
<li><a href="https://cloud.google.com/vertex-ai/docs/generative-ai/overview" target="_blank" rel="noopener noreferrer">Google Vertex AI</a></li>
<li><a href="https://www.anthropic.com/index/introducing-claude" target="_blank" rel="noopener noreferrer">Anthropic Claude</a></li>
<li><a href="https://ai.meta.com/llama/" target="_blank" rel="noopener noreferrer">Meta LLaMA</a></li>
<li><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">‚ÄúAttention is All You Need‚Äù (original paper)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" rel="noopener noreferrer">Large language model ‚Äì Wikipedia</a></li>
</ul>]]></content>
        <author>
            <name>Carol Soares</name>
            <uri>https://github.com/carolinesoarws</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="llm" term="llm"/>
        <category label="generative ai" term="generative ai"/>
        <category label="product-development" term="product-development"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Experience at TheDevConf 2025]]></title>
        <id>https://carolinesoarws.github.io/carol-soares-blog/blog/dtc-conference</id>
        <link href="https://carolinesoarws.github.io/carol-soares-blog/blog/dtc-conference"/>
        <updated>2025-04-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Hey everyone! üíª‚ú®]]></summary>
        <content type="html"><![CDATA[<p>Hey everyone! üíª‚ú® <br></p>
<p>It‚Äôs been about 9 months since I started working on developing solutions using artificial intelligence ‚Äî with a particular focus on generative AI. In recognition of my contributions, my company awarded me the opportunity to attend TDC ‚Äî The Developer Conference AI, that happen in S√£o Paulo, Brazil.</p>
<p>This conference is aimed at developers connecting with each other, discovering new trends, discussing best practices, sharing knowledge, etc. It was my first time attending a conference, and honestly, I felt like Sheldon! üòÇüòÇ</p>
<p align="center"></p><p><img decoding="async" loading="lazy" alt="Sheldon Cooper, a famous character from the TV sitcom The Big Bang Theory, wearing a red t-shirt, holding chopsticks and a plate, turning his head, and smiling with his mouth closed." src="https://carolinesoarws.github.io/carol-soares-blog/assets/images/sheldon-2183877f66927f36e40d0fbec60049c7.gif" width="498" height="268" class="img_ev3q"></p><p></p>
<p>I‚Äôm someone who, on the surface, seems sociable, but I hate being in large crowds and never really got excited about these types of events. I've always thought they were overrated. I don‚Äôt even believe in astrology, but I‚Äôll blame it on my sign today hahahaha.</p>
<p>The conference took place on March 26th and 27th, 2025, and it focused on artificial intelligence. There were several panels covering various topics related to generative AI. In general, the panels discussed how AI is being applied in different areas like healthcare, agriculture, software development, everyday life, and more. And I‚Äôd love to share some of the themes that impacted me the most.</p>
<p align="center"></p><p><img decoding="async" loading="lazy" alt="a hand holding tdc name tag card" src="https://carolinesoarws.github.io/carol-soares-blog/assets/images/IMG_7760-2f7cf879e09bc3ea05dcc805efb3f41d.jpeg" width="4032" height="3024" class="img_ev3q"></p><p></p>
<p>The first panel that really struck me was from a company that uses AI to monitor neonatal ICUs. Through the electrodes placed on the babies, data is collected and analyzed in real time by a system using generative AI. The case presented involved a newborn with complications. When the baby started having significant changes that required medical intervention, the system had already identified the issue <em>hours in advance</em> ‚Äî the baby was having an epileptic seizure. With this analysis, doctors were able to act quickly, and the baby survived. In fact, the baby is now healthy and growing well, under medical supervision of course. Incredible, right? I was deeply moved by this case!</p>
<p>The second impactful panel was about the use of generative AI in agriculture. They showed how AI is transforming the industry through soil, weather, and livestock analysis... The presenter even showed AI-powered cameras being used for these analyses, for example. One thing I was curious about was the stereotype that people in agriculture are resistant to technology. The speaker explained that the new generation in agribusiness is much more open to using technology in their daily work, and even many from older generations understand its importance now. It was really cool!!</p>
<p>The third panel that impressed me was a presentation by a team working on modernizing legacy code. With the help of generative AI, a parte of the code that was expected to take a year to be complete, actually took 6 months. Amazing, right? That‚Äôs a huge time savings!</p>
<p>What I enjoyed most about the talks I participated, was that the speakers emphasized the importance of using AI consciously and responsibly. And this goes way beyond just using AI for anything‚Äîit‚Äôs about knowing why you‚Äôre using it, applying prompt engineering to get accurate responses, validating whether the AI's response is correct, checking if it‚Äôs "hallucinating," and so on. Not to mention the environmental impact of AI usage, which is a real can of worms‚Äîgirl, it‚Äôs scary!</p>
<p>This conference was amazing! I had so much fun, learned a lot, and met some incredible professionals! For example, I participated in a mentorship focused on working on international projects, which is exactly the direction I want my career to go right now. I absolutely loved it and I think the experience is totally worth it!</p>
<p>Negative points:</p>
<ul>
<li>The location wasn‚Äôt great, and there weren‚Äôt any nearby restaurants to have lunch without a long walk‚Äîwhich I didn‚Äôt love.</li>
<li>The food experience was poor. The event had announced that there would be partner food vendors, but in the end, there weren‚Äôt any. There was a communication failure, which was a big deal since I spent the whole day there. Especially because I was alone and didn‚Äôt feel safe walking around that part of S√£o Paulo on my own.</li>
</ul>
<p>Positive points:</p>
<ul>
<li>The venue itself was really nice.</li>
<li>I got a bunch of free goodies, which was super fun!</li>
</ul>
<p align="center"></p><p><img decoding="async" loading="lazy" alt="ecobag that i got in the conference, the ecobag is white" src="https://carolinesoarws.github.io/carol-soares-blog/assets/images/IMG_7758-42dd02937b57361f043118ce3925efaf.jpeg" width="4032" height="3024" class="img_ev3q"></p><p></p>
<ul>
<li>The "silent presentation" format was the coolest part: basically, three panels were happening at the same time. We wore headphones and could switch stations at any time to follow whichever presentation we wanted.</li>
<li>I really enjoyed the networking, the spaces, the mentoring sessions, and the companies that were there!</li>
</ul>
<p>All in all, it was absolutely worth it!</p>]]></content>
        <author>
            <name>Carol Soares</name>
            <uri>https://github.com/carolinesoarws</uri>
        </author>
        <category label="generative AI" term="generative AI"/>
        <category label="innovation" term="innovation"/>
        <category label="learnings" term="learnings"/>
        <category label="artificial intelligence" term="artificial intelligence"/>
        <category label="technology" term="technology"/>
        <category label="future" term="future"/>
        <category label="creativity" term="creativity"/>
        <category label="research" term="research"/>
        <category label="trends" term="trends"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[6 Months in an Innovation Lab]]></title>
        <id>https://carolinesoarws.github.io/carol-soares-blog/blog/long-blog-post</id>
        <link href="https://carolinesoarws.github.io/carol-soares-blog/blog/long-blog-post"/>
        <updated>2025-03-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Hey everyone! üíª‚ú®]]></summary>
        <content type="html"><![CDATA[<p>Hey everyone! üíª‚ú® <br></p>
<p>Six months ago, I started working on an innovation project. The main idea of this project is to test innovative solutions for problems using Generative AI. It's been a completely new world for me, as until then, I had only worked on product delivery. Working in this lab completely took me out of my bubble, especially because I am a backend engineer. During this period, I've learned a few things:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="not-everything-can-be-solved-with-generative-ais">Not Everything Can Be Solved with Generative AIs<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/long-blog-post#not-everything-can-be-solved-with-generative-ais" class="hash-link" aria-label="Direct link to Not Everything Can Be Solved with Generative AIs" title="Direct link to Not Everything Can Be Solved with Generative AIs">‚Äã</a></h3>
<p>The tech world is as crazy as the release of a new pop diva's album. The revolution of some emerging technologies makes many people in the market, especially business leaders, rush to implement these solutions at any cost. When a pop diva releases an iconic album, it's literally written in the stars that all brands, trends, and even the fashion industry will ride that wave. The same happens in technology: when truly impactful innovation arises, everyone wants to adopt, adapt, and capitalize on it. The problem is that, often, this rush happens without a real understanding of whether that tool is truly the right solution for the problem.</p>
<p>What I love most about this project is that it forces me to think outside of my bubble and even question whether the solution I‚Äôm proposing really makes sense for the business problem we‚Äôre solving or if Generative AI meets our expectations. Not every problem needs Generative AI to be solved, but the fact that we reflect on the effectiveness of these technologies in our challenges completely changes the idea of "just using technology at any cost."</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="best-practices-and-automation-yes-always">Best Practices and Automation, Yes, Always!<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/long-blog-post#best-practices-and-automation-yes-always" class="hash-link" aria-label="Direct link to Best Practices and Automation, Yes, Always!" title="Direct link to Best Practices and Automation, Yes, Always!">‚Äã</a></h3>
<p>In this project, we deliver rapid prototypes. Therefore, we are constantly testing new solutions and making them available for evaluation. The fact that we deliver only prototypes <strong>does not</strong> mean that software best practices should be neglected. I‚Äôve felt firsthand how important it is to apply good development practices and have automated deployment in all projects.</p>
<p>Using new technology doesn‚Äôt mean we need to abandon best practices or leave them only partially structured. They exist for a good reason: to make the developer's life easier and increase delivery speed. It has been very satisfying to see the greatness of these practices applied in my daily work, especially aligned with Generative AI, which means that a new technology <em>should not override</em> everything else. I love software best practices, and once you work by following this model, you don't want to do things any other way.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-exponential-power-of-generative-ai">The Exponential Power of Generative AI<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/long-blog-post#the-exponential-power-of-generative-ai" class="hash-link" aria-label="Direct link to The Exponential Power of Generative AI" title="Direct link to The Exponential Power of Generative AI">‚Äã</a></h3>
<p>During this time, I had the chance to use some Generative AI models for our deliveries, and it‚Äôs fascinating to see the exponential power of these technologies. One of the most striking models was OpenAI‚Äôs embedding model, as well as the model for working with voice.</p>
<p>At one point, I had to work with RAG on a vector database, combined with an embedding model. It was <strong>soo</strong> cool to see the program's behavior when returning data based on search similarity, everything felt magical! But if there‚Äôs no good database foundation, things can backfire. Also, some libraries can be heavy in Python, so if you don‚Äôt have a machine that can handle it, you might end up with some headaches.</p>
<p>In my experience, I used chromadb as a vector database, and wow, that was a sentimental little database. Just one wrong configuration, and it doesn't work properly. At the time, I had to deploy it on AWS, and even though I configured communication ports for it to access the internet, it would pick any port except the one we wanted, and that was a pain! But for small tests, it behaved well, which makes me excited about the possibilities. I‚Äôm currently exploring other vector databases, but it was really cool to learn from chromadb. I didn‚Äôt know the concepts too deeply, but it was super interesting to work with.</p>
<p>What saved me many times was the fact that I had a powerful machine to work with. I‚Äôve crashed my PC about 4 times in a row testing some extremely heavy models and libraries, but my machine survived. Even working with AWS Lambda or EC2, the process of using the libraries can be slow depending on the installation process, and Docker was our ally in that fight. One thing that makes me reflect on Gen AI is the fact that we need to have a decent machine to work with some libraries and models, at least locally. At least in my experience, after we included Docker, it became much easier to work with these heavier libraries like langchain, a dream on a summer night, literally.</p>
<p>With the voice model, it was very interesting to notice the naturalness in the speech, especially with some accents, which really surprised me!! The model we tested for conversation flow had such a great tone that can be calibrated, which opens infinite possibilities for accessibility, and that's amazing!</p>
<p>Generative AI, when aligned correctly, is amazing and takes delivery standards to the next level! I‚Äôve learned to be flexible in this regard, the ability to test different models, aligned with best practices, is out of this world.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="women-in-power">Women in Power!<a href="https://carolinesoarws.github.io/carol-soares-blog/blog/long-blog-post#women-in-power" class="hash-link" aria-label="Direct link to Women in Power!" title="Direct link to Women in Power!">‚Äã</a></h3>
<p>In this project, many amazing, intelligent, and supportive people have passed through. But I‚Äôm very proud to say that the team is mostly female. What a joy it is to work with other women, share experiences‚Ä¶ I feel heard, welcomed, and embraced. A privilege!</p>
<p>These past few months have been great.</p>]]></content>
        <author>
            <name>Carol Soares</name>
            <uri>https://github.com/carolinesoarws</uri>
        </author>
        <category label="generative AI" term="generative AI"/>
        <category label="innovation" term="innovation"/>
        <category label="learnings" term="learnings"/>
        <category label="artificial intelligence" term="artificial intelligence"/>
        <category label="machine learning" term="machine learning"/>
        <category label="technology" term="technology"/>
        <category label="future" term="future"/>
        <category label="creativity" term="creativity"/>
        <category label="trends" term="trends"/>
    </entry>
</feed>