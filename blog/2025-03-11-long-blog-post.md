---
slug: long-blog-post
title: 6 Months in an Innovation Lab
authors: carolsoares
tags: [generative AI, innovation, learnings, artificial intelligence, machine learning, technology, future, creativity, trends]
---


Six months ago, I started working on an innovation project. The main idea of this project is to test innovative solutions for problems using Generative AI. It's been a completely new world for me, as until then, I had only worked on product delivery. Working in this lab completely took me out of my bubble, especially because I am a backend engineer. During this period, I've learned a few things:

### Not Everything Can Be Solved with Generative AI
The tech world is as crazy as the release of a new pop diva's album. The revolution of some emerging technologies makes many people in the market, especially business leaders, rush to implement these solutions at any cost. When a pop diva releases an iconic album, it's literally written in the stars that all brands, trends, and even the fashion industry will ride that wave. The same happens in technology: when truly impactful innovation arises, everyone wants to adopt, adapt, and capitalize on it. The problem is that, often, this rush happens without a real understanding of whether that tool is truly the right solution for the problem.

What I love most about this project is that it forces me to think outside of my bubble and even question whether the solution I’m proposing really makes sense for the business problem we’re solving or if Generative AI meets our expectations. Not every problem needs Generative AI to be solved, but the fact that we reflect on the effectiveness of these technologies in our challenges completely changes the idea of "just using technology at any cost."

### Best Practices and Automation, Yes, Always!
In this project, we deliver rapid prototypes. Therefore, we are constantly testing new solutions and making them available for evaluation. The fact that we deliver only prototypes **does not** mean that software best practices should be neglected. I’ve felt firsthand how important it is to apply good development practices and have automated deployment in all projects.

Using new technology doesn’t mean we need to abandon best practices or leave them only partially structured. They exist for a good reason: to make the developer's life easier and increase delivery speed. It has been very satisfying to see the greatness of these practices applied in my daily work, especially aligned with Generative AI, which means that a new technology *should not override* everything else. I love software best practices, and once you work by following this model, you don't want to do things any other way.

### The Exponential Power of Generative AI
During this time, I had the chance to use some Generative AI models for our deliveries, and it’s fascinating to see the exponential power of these technologies. One of the most striking models was OpenAI’s embedding model, as well as the model for working with voice.

At one point, I had to work with RAG on a vector database, combined with an embedding model. It was **soo** cool to see the program's behavior when returning data based on search similarity, everything felt magical! But if there’s no good database foundation, things can backfire. Also, some libraries can be heavy in Python, so if you don’t have a machine that can handle it, you might end up with some headaches.

In my experience, I used chromadb as a vector database, and wow, that was a sentimental little database. Just one wrong configuration, and it doesn't work properly. At the time, I had to deploy it on AWS, and even though I configured communication ports for it to access the internet, it would pick any port except the one we wanted, and that was a pain! But for small tests, it behaved well, which makes me excited about the possibilities. I’m currently exploring other vector databases, but it was really cool to learn from chromadb. I didn’t know the concepts too deeply, but it was super interesting to work with.

What saved me many times was the fact that I had a powerful machine to work with. I’ve crashed my PC about 4 times in a row testing some extremely heavy models and libraries, but my machine survived. Even working with AWS Lambda or EC2, the process of using the libraries can be slow depending on the installation process, and Docker was our ally in that fight. One thing that makes me reflect on Gen AI is the fact that we need to have a decent machine to work with some libraries and models, at least locally. At least in my experience, after we included Docker, it became much easier to work with these heavier libraries like langchain, a dream on a summer night, literally.

With the voice model, it was very interesting to notice the naturalness in the speech, especially with some accents, which really surprised me!! The model we tested for conversation flow had such a great tone that can be calibrated, which opens infinite possibilities for accessibility, and that's amazing!

Generative AI, when aligned correctly, is amazing and takes delivery standards to the next level! I’ve learned to be flexible in this regard, the ability to test different models, aligned with best practices, is out of this world.

### Women in Power!
In this project, many amazing, intelligent, and supportive people have passed through. But I’m very proud to say that the team is mostly female. What a joy it is to work with other women, share experiences… I feel heard, welcomed, and embraced. A privilege!

These past few months have been great.
